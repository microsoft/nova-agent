## NOVA & SLIDEQUEST
NOVA is an agentic framework that translates scientific queries into executable analysis pipelines by iteratively generating and running Python code. NOVA integrates 49 domain-specific tools (e.g., nuclei segmentation, whole-slide encoding) built on open-source software, and can also create new tools ad hoc.
To evaluate such systems, we present SlideQuest, a 90-question benchmark—verified by pathologists and biomedical scientists—spanning data processing, quantitative analysis, and hypothesis testing. Unlike prior biomedical benchmarks focused on knowledge recall or diagnostic QA, SlideQuest demands multi-step reasoning, iterative coding, and computational problem solving.

## What can NOVA do?
NOVA was developed to unify existing histopathology tools within a single framework that supports natural language interaction, making it accessible to clinicians with limited time or technical expertise. This integration not only facilitates large-scale analysis of complex data but also empowers users to drive discovery and generate new hypotheses.

SlideQuest was developed to enable the evaluation of dynamic agentic systems that require benchmarks that move beyond static question answering to capture the complexity of multi-step reasoning and data-scale analysis.
A detailed discussion of NOVA & SlideQuest, including how it was developed and tested, can be found in [our paper](https://arxiv.org/abs/2511.11324).

## Intended uses
NOVA is best suited for histopathology data analysis.
NOVA & SlideQuest are being shared with the research community to facilitate reproduction of our results and foster further research in this area.
NOVA & SlideQuest are intended to be used by domain experts who are independently capable of evaluating the quality of outputs before acting on them.

## Out-of-scope uses
NOVA is not well suited for other modalities than histopathology. Please explore the set of available tools to determine use case suitability.
We do not recommend using NOVA in commercial or real-world applications without further testing and development. It is being released for research purposes.
NOVA was not designed or evaluated for all possible downstream purposes. Developers should consider its inherent limitations as they select use cases, and evaluate and mitigate for accuracy, safety, and fairness concerns specific to each intended downstream use.
Without further testing and development, NOVA should not be used in sensitive domains where inaccurate outputs could suggest actions that lead to injury or negatively impact an individual's legal, financial, or life opportunities.
We do not recommend using NOVA in the context of high-risk decision making (e.g. in law enforcement, legal, finance, or healthcare).

## How to get started?
To begin using NOVA, checkout the [README](README.md) for necessary code, links, instructions on how to get started.

## Evaluation
NOVA was evaluated on its ability to complete histopathology data analysis via the SlideQuest benckmark that captures 4 categories of tasks, including pyramidal data interrogation (DataQA), cellular analysis (CellularQA), histology region of interest understanding (PatchQA) and gigapixel slide level experimentation (SlideQA).
A detailed discussion of our evaluation methods and results can be found in [our paper](https://arxiv.org/abs/2511.11324)

### Evaluation methods
We used Accuracy to measure NOVA’s performance. We enforced structured json outputs in SlideQuest enabling us to measure an accuracy score based on soft matching of the outputs against a predefined ground truth.
We compared the performance of NOVA against 3 different baselines (LLM only, LLM with python interpreter (PI), LLM with (PI) and retries) using the SlideQuest benchmark.
The model used for evaluation was GPT-4.1. For more on this specific model, please see [Introducing GPT-4.1 in the API | OpenAI](https://openai.com/index/gpt-4-1/).
Results may vary if NOVA is used with a different model based on its unique design, configuration and training.

### Evaluation results
At a high level, we found that NOVA performed 0.477 average score on all 4 categories of SlideQuest.

## Limitations
NOVA was developed for research and experimental purposes. Further testing and validation are needed before considering its application in commercial or real-world scenarios.
NOVA was designed and tested using the English language. Performance in other languages may vary and should be assessed by someone who is both an expert in the expected outputs and a native speaker of that language.
Outputs generated by AI may include factual errors, fabrication, or speculation. Users are responsible for assessing the accuracy of generated content. All decisions leveraging outputs of the system should be made with human oversight and not be based solely on system outputs.
NOVA inherits any biases, errors, or omissions produced by its base model. Developers are advised to choose an appropriate base LLM/MLLM carefully, depending on the intended use case.
NOVA uses the GPT-4.1 model. See [Introducing GPT-4.1 in the API | OpenAI](https://openai.com/index/gpt-4-1/) to understand the capabilities and limitations of this model.
NOVA inherits any biases, errors, or omissions characteristic of its training data, which may be amplified by any AI-generated interpretations.
There has not been a systematic effort to ensure that systems using NOVA are protected from security vulnerabilities such as indirect prompt injection attacks. Any systems using it should take proactive measures to harden their systems as appropriate.

## Best practices
Better performance can be achieved by GPT-4.1 or GPT-5 as core LLM.
We strongly encourage users to use LLMs/MLLMs that support robust Responsible AI mitigations, such as Azure Open AI (AOAI) services. Such services continually update their safety and RAI mitigations with the latest industry standards for responsible use. For more on AOAI’s best practices when employing foundations models for scripts and applications:
- [What is Azure AI Content Safety?](https://learn.microsoft.com/en-us/azure/ai-services/content-safety/overview)
- [Overview of Responsible AI practices for Azure OpenAI models](https://learn.microsoft.com/en-us/legal/cognitive-services/openai/overview)
- [Azure OpenAI Transparency Note](https://learn.microsoft.com/en-us/legal/cognitive-services/openai/transparency-note)
- [OpenAI’s Usage policies](https://openai.com/policies/usage-policies)
- [Azure OpenAI’s Code of Conduct](https://learn.microsoft.com/en-us/legal/cognitive-services/openai/code-of-conduct)

Users are responsible for sourcing their datasets legally and ethically. This could include securing appropriate rights, ensuring consent for use of audio/images, and/or the anonymization of data prior to use in research.
Users are reminded to be mindful of data privacy concerns and are encouraged to review the privacy policies associated with any models and data storage solutions interfacing with NOVA.
It is the user’s responsibility to ensure that the use of NOVA complies with relevant data protection regulations and organizational guidelines.
Developers should follow transparency best practices and inform end-users they are interacting with an AI system.

## LICENSE
### MIT License
Nothing disclosed here, including the Out of Scope Uses section, should be interpreted as or deemed a restriction or modification to the license the code is released under.

## TRADEMARKS
This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.

## CONTACT
This research was conducted by members of [Microsoft Research](https://www.microsoft.com/en-us/research/), [Mahmood Lab – Computational Pathology – Computational and Quantitive Pathology at Harvard](https://faisal.ai/) and [The Williamson Lab](https://www.williamsonlab.org/).  We welcome feedback and collaboration from our audience. If you have suggestions, questions, or observe unexpected/offensive behavior in our technology, please contact us at BioMedicalImaging@microsoft.com.
If the team receives reports of undesired behavior or identifies issues independently, we will update this repository with appropriate mitigations.
